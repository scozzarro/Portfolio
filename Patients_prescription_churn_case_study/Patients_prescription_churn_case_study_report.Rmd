---
title: "Patients prescription churn case study"
author: "Gabriel Scozzarro"
date: "26/4/2021"
output: hrbrthemes::ipsum_pdf
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,  dev = "cairo_pdf")
```

## 1.0 Introduction

This case study origin from the problem that many retail shops has, that is customer retention. One way to tackle this problem is understand when an already acquired customer is churning.

But what is customer churn? Customer churn refers to when a customer (player, subscriber, user, etc. depending on industry) ceases his or her relationship with the company. Online businesses typically treat a customer as churned once a particular amount of time has elapsed since the customer's last interaction with the site or service. The full cost of customer churn includes both lost revenue and the marketing costs involved with replacing those customers with new ones. Reducing customer churn is a key business goal of every online business.

The ability to predict that a particular customer is at a high risk of churning, while there is still time to do something about it, represents a huge additional potential revenue source for every online business. Besides the direct loss of revenue that results from a customer abandoning the business, the costs of initially acquiring that customer may not have already been covered by the customer's spending to date. (In other words, acquiring that customer may have actually been a losing investment.) Furthermore, it is always more difficult and expensive to acquire a new customer than it is to retain current paying customers.

### 1.1 Scope of work & Business task

In this case study I will focus on predicting customer churn for a pharmacy retail group with many shops around the country. Furthermore a complete data analysis and exploration is performed, including insight on the prediction power of each data features which can be exploited to design customer retantion strategies.

## 2.0 Data

The data set used is avaible on [**Kaggle**](https://www.kaggle.com) under the name of [**Customer Churn Prediction \|\| Pharmaceutical Data**](https://www.kaggle.com/mishra5001/customer-churn-prediction-pharmaceutical-data). This data set is provided in csv format and has a Kaggle usability score of 8.8 which mean it was already cleaned and feature was drescribed for easy understanding. The data set was created in Feb 2021 and it contain pharmacies transaction and bill for a period of 5 month from the end of Apr 2019 to Sep 2019. In addition to the main data set it also provided a test dataset to test the prediction efficacy.

## 3.0 Tools and process

The analysis was performed using R coding language. A complete list of R packages, a data log and the source code are all avaible on the project github repository at this [**link**](https://github.com/scozzarro/Portfolio/tree/main/Patients_prescription_churn_case_study).

```{r Tools and process, warning = FALSE, error = FALSE, message = FALSE, echo = FALSE}
#1.0 Library & Tools ----
library(tidyverse)
library(lubridate)
library(skimr)
library(visdat)
library(RColorBrewer)
library(ppsr)
library(correlationfunnel)
library(tidymodels)
library(xgboost)
library(vip)
library(caret)
library(hrbrthemes)

#Rmd tools
library(Cairo)
library(extrafont)
library(kableExtra)

extrafont::loadfonts()



#2.0 Data ----

##2.1 Importing ----

purchase_data_Apr_Sep<- read.csv('Data/purchase_data_bill_level_sept.csv')
purchase_data_test_Oct<- read.csv('Data/out_of_time_test_oct.csv')

#Sanity check

#skim_without_charts(purchase_data_Apr_Sep)
#skim_without_charts(purchase_data_test_Oct)

purchase_data_Apr_Sep$created_at_bill<- ymd_hms(purchase_data_Apr_Sep$created_at_bill)
purchase_data_Apr_Sep$payment_method[which(purchase_data_Apr_Sep$payment_method == '')]<- 'not specified'
```

## 4.0 Analysis

Data contains information about `r n_distinct(purchase_data_Apr_Sep$bill_ref_id)` transactions made in `r n_distinct(purchase_data_Apr_Sep$store_ref_id)` stores, by `r n_distinct(purchase_data_Apr_Sep$customer_re_id)` distinct users. The average receipt value was `r mean(purchase_data_Apr_Sep$total_spend_bill)`\$.

Tha sales analysis showed a steady number of sales from april to july with a costant increase in august and september. The highest number of sales was made on monday, while from tuesday to saturday we observed a slightly lower and constant value. Sunday has the worst sales rate, almost halved compared to the others.

```{r Analysis 1, warning = FALSE, error = FALSE, message = FALSE, echo = FALSE, out.width = '50%'}
purchase_data_Apr_Sep %>% ggplot(aes(month(created_at_bill, label = TRUE), fill = month(created_at_bill, label = TRUE))) +
                          geom_bar(stat = 'count') +
                          scale_fill_brewer(palette = 'Set3') +
                          theme_ipsum() +
                          theme(legend.position = 'none') +
                          labs(title = 'Number of sales by months') +
                          xlab('Months') +
                          ylab('Number of sales')

purchase_data_Apr_Sep %>% group_by(week_day = wday(created_at_bill,label = TRUE)) %>%
                          summarise(Number_of_sales = n()) %>%
                          ggplot(aes(week_day, Number_of_sales, fill = week_day)) +
                          geom_bar(stat = 'identity') +
                          scale_fill_brewer(palette = 'Set3') +
                          theme_ipsum() +
                          theme(legend.position = 'none') +
                          labs(title = 'Number of sales by day of the week') +
                          xlab('Day of the week') +
                          ylab('Number of sales')

```

The favorite part of the day was the post meridian (pm) with a concentration on the between 17:00 and 22:00.

```{r Analysis 2, warning = FALSE, error = FALSE, message = FALSE, echo = FALSE, out.width = '50%'}

purchase_data_Apr_Sep %>% mutate(am_pm = ifelse(am(created_at_bill) == TRUE, 'am', 'pm')) %>%
                          group_by(am_pm) %>%
                          summarise(Number_of_sales = n()) %>%
                          ggplot(aes(am_pm, Number_of_sales, fill = am_pm)) +
                          geom_bar(stat = 'identity') +
                          scale_fill_brewer(palette = 'Set1') +
                          theme_ipsum() +
                          theme(legend.position = 'none') +
                          xlab('Part of the day') +
                          ylab('Number of sales') +
                          labs(title = 'Number of sales by part of the day')

purchase_data_Apr_Sep %>% mutate(created_at_bill = hour(round_date(created_at_bill, unit = 'hour'))) %>%
                          group_by(created_at_bill) %>%
                          summarise(Number_of_sales = n()) %>%
                          ggplot(aes(created_at_bill, Number_of_sales)) +
                          geom_bar(stat = 'identity', fill = 'darkorange2') +
                          theme_ipsum() +
                          theme(legend.position = 'none') +
                          xlab('Hours of the day') +
                          ylab('Number of sales') +
                          labs(title = 'Number of sales by hours of the day')
```

\pagebreak

In the following plot are showed the top 10 store by number of sales.

```{r Analysis 3, warning = FALSE, error = FALSE, message = FALSE, echo = FALSE, out.width = '50%'}

purchase_data_Apr_Sep %>% group_by(store_ref_id) %>%
                          summarise(Number_of_sales = n()) %>%
                          top_n(10, wt = Number_of_sales) %>%
                          arrange(Number_of_sales) %>% 
                          ggplot(aes(as.factor(store_ref_id), Number_of_sales , fill = as.factor(store_ref_id))) +
                          geom_bar(stat = 'identity') +
                          scale_fill_brewer(palette = 'Set3') +
                          theme_ipsum() +
                          theme(legend.position = 'none') +
                          xlab('Store Id') +
                          ylab('Number of sales') +
                          labs(title = 'Best 10 stores by number of sales')

different_store_visit<- purchase_data_Apr_Sep %>% group_by(customer_ref_id) %>%
                                                  summarise(store_visited = n_distinct(store_ref_id)) %>%
                                                  arrange(desc(store_visited))

different_store_visit %>% ggplot(aes(store_visited)) +
                          geom_density(col='lightseagreen', fill = 'grey', alpha = 0.7, size= 1 ) +
                          xlim(10,40)+
                          theme_ipsum() +
                          xlab('Different store visited') +
                          labs(title = 'Dirrefent stored visited distribution', 
                               caption = 'Data interval modified for plot reason')

```

We can observe that the majority of the customer did the first purchase in april, this mean that the customer was acquired in april or previously. Not taking in consideration april the best month for acquisition was may the other has a steady increase. Overall the undisputed favorite payment method was cash. We note also that many customer made purchases in different store denoting a fidelization of that customer.

```{r Analysis 4, warning = FALSE, error = FALSE, message = FALSE, echo = FALSE, out.width = '50%'}

purchase_data_Apr_Sep %>% group_by(customer_ref_id) %>%
                          summarise(first_bill = min(month(created_at_bill, label = TRUE))) %>%
                          ggplot(aes(first_bill, fill = first_bill)) +
                          geom_bar(stat = 'count') +
                          scale_fill_brewer(palette = 'Set2') +
                          theme_ipsum() +
                          theme(legend.position = 'none') +
                          xlab('New customers') +
                          labs(title = 'New customer per month')
```

\pagebreak

Overall the undisputed most used payment method was cash, but we can see that as the purchase value rise the payment method change.

```{r Analysis 5, warning = FALSE, error = FALSE, message = FALSE, echo = FALSE, out.width = '50%'}

purchase_data_Apr_Sep %>% ggplot(aes(payment_method, fill = payment_method)) +
                          geom_bar(stat = 'count') +
                          scale_fill_brewer(palette = 'Set2') +
                          theme_ipsum() +
                          theme(legend.position = 'none') +
                          xlab('Payment method') +
                          labs(title = 'Payment method frequency')

purchase_data_Apr_Sep %>% group_by(payment_method) %>%
                          summarise(avg_payment = mean(total_spend_bill)) %>%
                          arrange(desc(avg_payment)) %>%
                          ggplot(aes(payment_method, avg_payment, fill = payment_method)) +
                          geom_bar(stat = 'identity') +
                          scale_fill_brewer(palette = 'Set2') +
                          scale_y_comma()+
                          theme_ipsum() +
                          theme(legend.position = 'none') +
                          xlab('Payment method') +
                          ylab('Average transaction') +
                          labs(title = 'Average transaction per payment method')
```

```{r Analysis 6, warning = FALSE, error = FALSE, message = FALSE, echo = FALSE, out.width = '100%'}

purchase_data_Apr_Sep %>% ggplot(aes(round(total_spend_bill), fill = payment_method)) +
                          geom_density(alpha = 0.4) +
                          scale_x_comma(limits = c(0,5000)) +
                          theme_ipsum() +
                          xlab('Transaction value $') +
                          labs(title = 'Distribution of payment method by a purchase value', 
                               caption = 'Purchase value was limited to 5000$')
                        
```

## 5.0 Prediction model

The desired prediction model need to predict the probability of each user to churn in september 2019. To build a prediction model based on this data set, a process called feature selection and engineering was necessary. The data frame created for train and validate the model was used also to evaluate the prediction power, correlation and importance of the features created. As target value a specific feature was created with the name of 'churn_in_sep' and can assume a logic value of 0 if the user stayed also in september and 1 it churn.

After this process, from the main data set a train and validation data frame were created. The evaluation of the model was made using AUC metrics.

```{r Prediction model 1, warning = FALSE, error = FALSE, message = FALSE, echo = FALSE}

dummy<- purchase_data_Apr_Sep %>% filter(month(created_at_bill) < 9) %>%
                                  group_by(customer_ref_id, month = month(created_at_bill)) %>%
                                  summarise(n= n_distinct(bill_ref_id))

dummy<- dummy %>% group_by(customer_ref_id) %>%
                  summarise(avg_visit = mean(n))

data_model_train<- purchase_data_Apr_Sep %>% filter(month(created_at_bill) < 9) %>%
                                             group_by(customer_ref_id) %>%
                                             summarise(avg_spent =  mean(total_spend_bill),
                                                       avg_ethical_drug = mean(quantity_ethical),
                                                       avg_generic_drugs = mean(quantity_generic),
                                                       avg_surgical_drugs = mean(quantity_surgical),
                                                       avg_ayurvedic_drugs = mean(quantity_ayurvedic),
                                                       avg_general_drugs = mean(quantity_general),
                                                       avg_otc_drugs = mean(quantity_otc),
                                                       avg_chronic_drugs = mean(quantity_chronic),
                                                       avg_acute_drugs = mean(quantity_acute),
                                                       avg_h1_drugs = mean(quantity_h1),
                                                       avg_drugs_per_bill = mean(total_quantity_bill),
                                                       avg_type_of_drugs_per_bill = mean(num_drugs_bill))

data_model_train$avg_visit<- dummy$avg_visit

dummy<- purchase_data_Apr_Sep %>% group_by(customer_ref_id) %>%
                                  summarise(sep_bill = sum(ifelse(month(created_at_bill) == 9, 1, 0)))

dummy$churn_in_sep<- ifelse(dummy$sep_bill == 0, 1, 0)

data_model_train<- left_join(data_model_train, dummy, by = "customer_ref_id")
data_model_train$churn_in_sep<- as.factor(data_model_train$churn_in_sep)

data_model_train<- data_model_train[,-which(colnames(data_model_train) == 'sep_bill')]

data_model_train_prop<-prop.table(table(data_model_train$churn_in_sep))

data_model<- data_model_train

##4.2 Create data for validation ----
validation_index<- createDataPartition(data_model_train$churn_in_sep, p = 0.3, list = FALSE)
data_model_validation<- data_model_train[validation_index,]
data_model_train<- data_model_train[-validation_index,]

##4.3 Create data for test ---- 

data_model_test<- purchase_data_Apr_Sep %>% group_by(customer_ref_id) %>%
                                            summarise(avg_spent =  mean(total_spend_bill),
                                                      avg_ethical_drug = mean(quantity_ethical),
                                                      avg_generic_drugs = mean(quantity_generic),
                                                      avg_surgical_drugs = mean(quantity_surgical),
                                                      avg_ayurvedic_drugs = mean(quantity_ayurvedic),
                                                      avg_general_drugs = mean(quantity_general),
                                                      avg_otc_drugs = mean(quantity_otc),
                                                      avg_chronic_drugs = mean(quantity_chronic),
                                                      avg_acute_drugs = mean(quantity_acute),
                                                      avg_h1_drugs = mean(quantity_h1),
                                                      avg_drugs_per_bill = mean(total_quantity_bill),
                                                      avg_type_of_drugs_per_bill = mean(num_drugs_bill))

dummy<- purchase_data_Apr_Sep %>% group_by(customer_ref_id, month = month(created_at_bill)) %>%
                                  summarise(n= n_distinct(bill_ref_id))

dummy<- dummy %>% group_by(customer_ref_id) %>%
                  summarise(avg_visit = mean(n))

data_model_test$avg_visit<- dummy$avg_visit

data_model_test$churn_in_oct<- purchase_data_test_Oct$oct_purchase_flag

```

Starting from the original data set, the target value inside the data frame prepared for the train and validation of the model has the following proportion: __`r round(data_model_train_prop[[1]]*100)`% of all users stays also in september, `r round(data_model_train_prop[[2]]*100)`% of them churn__. This mean that the original data was significantly unbalanced and a perfect prediction system is not possible. In the future work section I will present possible solution to this problem.

As shown in the following plot the most useful feature are the average quantity of visit made by the user and the the average quantity of drug for chronic diseases witch has a lot of sense since chronic diseases requires complex and prolonged treatment.

```{r Prediction model 2, warning = FALSE, error = FALSE, message = FALSE, echo = FALSE, out.width = '100%'}
data_model_ppsr<- data_model %>% select(-customer_ref_id) %>%
                                 visualize_pps(do_parallel = TRUE)

data_model_ppsr + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + ggtitle('Predictive power score')
```

```{r Prediction model 3, warning = FALSE, error = FALSE, message = FALSE, echo = FALSE, out.width = '50%',results = "hide"}



data_model_binned<- data_model %>% select(-customer_ref_id) %>%
                                   binarize()

data_model_binned %>% correlate(target = churn_in_sep__1) %>%
                      plot_correlation_funnel() +
                      geom_point(size = 3, color = 'aquamarine3') +
                      theme_ipsum()

recipe_spec <- recipe(churn_in_sep ~ ., data = data_model) %>%
               step_rm(customer_ref_id) %>%
               step_dummy(all_nominal(), -churn_in_sep)

#recipe_spec %>% prep() %>% juice() %>% glimpse()

fit_xgb <- workflow() %>%
           add_model(boost_tree(mode = "classification") %>% set_engine("xgboost")) %>%
           add_recipe(recipe_spec) %>%
           fit(data_model)

fit_xgb$fit$fit$fit %>% vip()

```

\pagebreak

For the prediction model, the approach taken was a generalist one, more a starting point rather than a complex and definitive solution. Using the [**H2o.ai**](https://www.h2o.ai/) platform in auto machine learning configuration, I was able to create different models using a variety of machine learning algorithms.

```{r Prediction model 4, warning = FALSE, error = FALSE, message = FALSE, echo = FALSE, out.width = '50%',results = "hide"}
library(h2o)

h2o.init(nthreads = -1)

train_h20<- as.h2o(data_model_train)
validation_h20<- as.h2o(data_model_validation)
test_h2o<- as.h2o(data_model_test)

x_h2o<- c(1:14)
y_h2o<- 15

###4.5.1 H2o auto machine learning 

h2o_aml <- h2o.automl(x = x_h2o, y = y_h2o,
                      training_frame = train_h20,
                      validation_frame = validation_h20,
                      nfolds = 10,
                      max_models = 10,
                      max_runtime_secs_per_model = 600,
                      stopping_metric = 'AUC',
                      stopping_rounds = 4,
                      seed = 123)

h2o_aml_lb <- h2o_aml@leaderboard

h2o_aml_pred <- h2o.predict(h2o_aml@leader, validation_h20[,1:14])

```

As expected from the unbalanced data frame the prediction model is more sensible in predict customer that will churn. To evaluate the best model, the metric *AUC* was used. AUC stands for Area under the ROC Curve (showed in the picture below) and it measures the entire two-dimensional area underneath the entire ROC curve (think integral calculus). AUC provides an aggregate measure of performance across all possible classification thresholds. One way of interpreting AUC is as the probability that the model ranks a random positive example more highly than a random negative example.

According to this metric the best model created was an stacked ensemble generated from overlap different algorithms.

```{r Prediction model 5, warning = FALSE, error = FALSE, message = FALSE, echo = FALSE, out.width = '50%'}
lb<- head(h2o_aml_lb,5)

lb %>% kable('latex', digits = 10, caption = 'Auto machine learning leaderboard', booktabs = T) %>% kable_styling(full_width = FALSE, font_size = 11, latex_options = c("striped", 'condensed','scale_down')) 

leader_perf<- h2o.performance(h2o_aml@leader, validation_h20)


leader_perf@metrics$max_criteria_and_metric_scores %>% kable('latex', caption = 'Best model maximum metrics', booktabs = T) %>% kable_styling(full_width = T, font_size = 9, latex_options = c("striped", 'condensed','scale_down',"hold_position"))

leader_cf<- h2o.confusionMatrix(h2o_aml@leader) 

leader_cf %>% kable('latex', caption = 'Best model confusion matrix', booktabs = T) %>% kable_styling(full_width = T, font_size = 9, latex_options = c("striped", 'condensed','scale_down',"hold_position")) 

plot(leader_perf, type = 'roc')

plot(leader_perf, type = 'pr')

h2o.shutdown(prompt = FALSE)

```
\pagebreak

## 6.0 Conclusion

Churn Prediction was done performed and results were acceptable. The data set creation and feature engineering were the complicated part of this project. Higher accuracy cannot be achieved simply in this type of data set. Training the previous month data set, we can predict the next months customers status in churn prediction.

## 7.0 Future work

Since the unbalanced nature of the data provide and the impossibility to gather new, a synthetic data augmentation process can be applied using for example ROSE technique.
